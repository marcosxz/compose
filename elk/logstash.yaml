# https://www.docker.elastic.co
version: '3'

networks:
  elastic:
    driver: bridge

volumes:
  logstash.node01:
    driver: local
  logstash.node02:
    driver: local

services:
  logstash.node01:
    image: logstash:7.14.1
    container_name: logstash.node01
    ports:
      - 9600:9600
      - 8088:8088
      - 8514:8514/udp
    networks:
      - elastic
    volumes:
      - ./logstash.node01/data:/usr/share/logstash/data
      - ./elasticsearch.certs:/usr/share/logstash/config/certificates
      # - ./logstash.node01/pipeline:/usr/share/logstash/pipeline
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
    environment:
      TZ: 'Asia/Shanghai'
      PIPELINE_ID: "main"
      PIPELINE_WORKERS: 2
      PIPELINE_BATCH_SIZE: 125
      PIPELINE_BATCH_DELAY: 50
      XPACK_MONITORING_ENABLED: "true"
      XPACK_MONITORING_ELASTICSEARCH_SNIFFING: "true"
      XPACK_MONITORING_ELASTICSEARCH_HOSTS: [ "https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200" ]
      XPACK_MONITORING_ELASTICSEARCH_USERNAME: "elastic"
      XPACK_MONITORING_ELASTICSEARCH_PASSWORD: "VVW0QqhyXNxGImWt0JF5"
      XPACK_MONITORING_ELASTICSEARCH_SSL_CERTIFICATE_AUTHORITY: "/usr/share/logstash/config/certificates/ca/ca.crt"
      CONFIG_DEBUG: "true"
      CONFIG_STRING: |
        input {
            kafka {
                bootstrap_servers => "0.0.0.0:9092"
                topics => ["logstash"]
                group_id => "logstash.node01"
                enable_auto_commit => true
                auto_commit_interval_ms => 3000
                auto_offset_reset => "latest"
                consumer_threads => 1
                connections_max_idle_ms => 60000
                heartbeat_interval_ms => 3000
                decorate_events => "basic"
            }
        }

        filter {
            if [@metadata][kafka][topic] == "logstash" {
                json {
                    source => "message"
                    target => "[@metadata][message_ctx]"
                }
                if [@metadata][message_ctx][agent][type] == "filebeat" {
                    if [@metadata][message_ctx][message] {
                        mutate {
                            rename => {
                                "[@metadata][message_ctx]" => "[@metadata][filebeat_ctx]"
                            }
                            replace => {
                                "message" => "%{[@metadata][filebeat_ctx][message]}"
                            }
                        }
                    }
                    if [@metadata][filebeat_ctx][log][file][path] == "/var/log/filebeat/nginx/access.log" {
                        json {
                            source => "message"
                            target => "[@metadata][message_ctx]"
                        }
                    }
                    if [@metadata][filebeat_ctx][log][file][path] == "/var/log/filebeat/nginx/error.log" {
                        mutate {
                            add_field => {
                                "[@metadata][message_ctx][app]" => "all.nginx.error"
                            }
                        }
                    }
                }

                if ![@metadata][message_ctx][app] {
                    mutate {
                        add_field => {
                            "[@metadata][message_ctx][app]" => "raw.log"
                        }
                    }
                }

                if [@metadata][message_ctx][app] {
                    mutate {
                        add_field => {
                            "[app]" => "%{[@metadata][message_ctx][app]}"
                            "[@metadata][app_index]" => "logstash-%{[@metadata][message_ctx][app]}-%{+YYYY.MM.dd}"
                        }
                    }
                }
                 if [@metadata][message_ctx][ts] {
                    mutate {
                        add_field => {
                            "[ts]" => "%{[@metadata][message_ctx][ts]}"
                        }
                    }
                }
                if [@metadata][message_ctx][level] {
                    mutate {
                        add_field => {
                            "[level]" => "%{[@metadata][message_ctx][level]}"
                        }
                    }
                }
                if [@metadata][message_ctx][caller] {
                    mutate {
                        add_field => {
                            "[caller]" => "%{[@metadata][message_ctx][caller]}"
                        }
                    }
                }
                if [@metadata][message_ctx][geo_ip] {
                    mutate {
                        add_field => {
                            "[geo_ip]" => "%{[@metadata][message_ctx][geo_ip]}"
                        }
                    }
                }
                if [@metadata][message_ctx][remote_addr] {
                    mutate {
                        add_field => {
                            "[geo_ip]" => "%{[@metadata][message_ctx][remote_addr]}"
                        }
                    }
                }
            }

            if [geo_ip] {
                geoip {
                    source => "geo_ip"
                    cache_size => 65535
                }
            }
        }

        output {
            stdout {
                codec => rubydebug {
                    metadata => false
                }
            }
            if [@metadata][kafka][topic] == "logstash" {
                elasticsearch {
                    hosts => ["https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200"]
                    index => "%{[@metadata][app_index]}"
                    retry_initial_interval => 3
                    retry_max_interval => 64
                    retry_on_conflict => 3
                    timeout => 5
                    user => "elastic"
                    password => "elastic123"
                    ssl => true
                    cacert => "/usr/share/logstash/config/certificates/ca/ca.crt"
                }
            }
        }

  logstash.node02:
    image: logstash:7.14.1
    container_name: logstash.node02
    ports:
      - 9601:9600
      - 8089:8088
      - 8515:8514/udp
    networks:
      - elastic
    volumes:
      - ./logstash.node02/data:/usr/share/logstash/data
      - ./elasticsearch.certs:/usr/share/logstash/config/certificates
      # - ./logstash.node02/pipeline:/usr/share/logstash/pipeline
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
    environment:
      TZ: 'Asia/Shanghai'
      PIPELINE_ID: "main"
      PIPELINE_WORKERS: 2
      PIPELINE_BATCH_SIZE: 125
      PIPELINE_BATCH_DELAY: 50
      XPACK_MONITORING_ENABLED: "true"
      XPACK_MONITORING_ELASTICSEARCH_SNIFFING: "true"
      XPACK_MONITORING_ELASTICSEARCH_HOSTS: [ "https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200" ]
      XPACK_MONITORING_ELASTICSEARCH_USERNAME: "elastic"
      XPACK_MONITORING_ELASTICSEARCH_PASSWORD: "VVW0QqhyXNxGImWt0JF5"
      XPACK_MONITORING_ELASTICSEARCH_SSL_CERTIFICATE_AUTHORITY: "/usr/share/logstash/config/certificates/ca/ca.crt"
      CONFIG_DEBUG: "true"
      CONFIG_STRING: |
        input {
          syslog {
              type => "syslog"
              host => "0.0.0.0"
              port => "8514"
          }
          http {
              type => "httplog"
              host => "0.0.0.0"
              port => "8088"
              additional_codecs => {"text/plain"=>"json"}
              codec => "json"
              threads => 8
              ssl => false
          }
          kafka {
              type => "kafkalog"
              bootstrap_servers => "0.0.0.0:9092"
              topics => ["logstash"]
              group_id => "logstash.node02"
              enable_auto_commit => true
              auto_commit_interval_ms => 3000
              auto_offset_reset => "latest"
              consumer_threads => 1
              connections_max_idle_ms => 60000
              heartbeat_interval_ms => 3000
              codec => "json"
          }
        }

        filter {
            if [type] == "syslog" and [program] {
                mutate {
                    add_field => { "[@metadata][es_index]" => "logstash-%{program}_%{+YYYYMMdd}" }
                }
                if [program] == "nginx_access" {
                    json {
                        source => "message"
                        remove_field => ["message"]
                    }
                }
            }

            if [type] == "httplog" and [app] {
                mutate {
                    add_field => { "[@metadata][es_index]" => "logstash-%{app}_%{+YYYYMMdd}" }
                }
            }

            if [type] == "kafkalog" and [agent][type] == "filebeat" {
                if [log][file][path] == "/var/log/filebeat/nginx/access.log" {
                    json {
                        source => "message"
                        remove_field => ["message"]
                    }
                }
                if [log][file][path] == "/var/log/filebeat/nginx/error.log" {
                    mutate {
                        add_field => { "[app]" => "all_nginx_error" }
                    }
                }
            }

            if [type] == "kafkalog" and [app] {
                mutate {
                    add_field => { "[@metadata][es_index]" => "logstash-%{app}_%{+YYYYMMdd}" }
                }
            }

            if ([type] not in ["syslog", "httplog", "kafkalog"]) or (![program] and ![app]) {
                mutate {
                    add_field => { "[@metadata][es_index]" => "logstash-default_%{+YYYYMMdd}" }
                }
            }

            if [ip] {
                geoip {
                    source => "ip"
                }
            }
            if [remote_addr] {
                geoip {
                    source => "remote_addr"
                }
            }

            if [type] == "syslog" {
                mutate {
                    remove_field => ["program"]
                    remove_field => ["timestamp"]
                    remove_field => ["severity"]
                    remove_field => ["priority"]
                    remove_field => ["facility"]
                    remove_field => ["facility_label"]
                    remove_field => ["logsource"]
                    remove_field => ["severity_label"]
                }
            }
            if [type] == "httplog" {
                mutate {
                    remove_field => ["headers"]
                }
            }
            if [type] == "kafkalog" and [agent][type] == "filebeat" {
                mutate {
                    remove_field => ["agent_"]
                    remove_field => ["input"]
                    remove_field => ["host"]
                    remove_field => ["log"]
                    remove_field => ["ecs"]
                }
            }
        }

        output {
            stdout { codec => rubydebug }

            if [type] == "syslog" {
                elasticsearch {
                    hosts => ["https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200"]
                    index => "%{[@metadata][es_index]}"
                    retry_initial_interval => 3
                    retry_max_interval => 64
                    retry_on_conflict => 3
                    timeout => 5
                    user => "elastic"
                    password => "VVW0QqhyXNxGImWt0JF5"
                    ssl => true
                    cacert => "/usr/share/logstash/config/certificates/ca/ca.crt"
                }
            }

            if [type] == "httplog" {
                elasticsearch {
                    hosts => ["https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200"]
                    index => "%{[@metadata][es_index]}"
                    retry_initial_interval => 3
                    retry_max_interval => 64
                    retry_on_conflict => 3
                    timeout => 5
                    user => "elastic"
                    password => "VVW0QqhyXNxGImWt0JF5"
                    ssl => true
                    cacert => "/usr/share/logstash/config/certificates/ca/ca.crt"
                }
            }

            if [type] == "kafkalog" {
                elasticsearch {
                    hosts => ["https://elasticsearch.node01:9200","https://elasticsearch.node02:9200","https://elasticsearch.node03:9200"]
                    index => "%{[@metadata][es_index]}"
                    retry_initial_interval => 3
                    retry_max_interval => 64
                    retry_on_conflict => 3
                    timeout => 5
                    user => "elastic"
                    password => "VVW0QqhyXNxGImWt0JF5"
                    ssl => true
                    cacert => "/usr/share/logstash/config/certificates/ca/ca.crt"
                }
            }
        }


